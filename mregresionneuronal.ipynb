{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6cd2c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: MLflow no está instalado. El código correrá igual, pero sin registrar experimentos.\n",
      "Shape del DataFrame: (40550, 147)\n",
      "Primeras columnas: ['id', 'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'price', 'minimum_nights', 'maximum_nights', 'number_of_reviews', 'reviews_per_month', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'neighbourhood_cleansed_Barnet']\n",
      "Usaremos la columna 'price' como variable objetivo (y).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Intentamos importar MLflow (si no está instalado, el código\n",
    "# sigue funcionando pero sin registrar experimentos)\n",
    "# --------------------------------------------------------------\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.keras as mlflow_keras\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Aviso: MLflow no está instalado. \"\n",
    "          \"El código correrá igual, pero sin registrar experimentos.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Fijamos semillas para reproducibilidad básica\n",
    "# --------------------------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ==============================================================\n",
    "# 1. CARGA DEL CONJUNTO DE DATOS LIMPIO\n",
    "# ==============================================================\n",
    "\n",
    "# Ruta al archivo limpio (ajusta el nombre si es necesario)\n",
    "DATA_PATH = \"listings_model_no_outliers.csv\"\n",
    "\n",
    "# Leemos el CSV en un DataFrame\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Mostramos información básica para verificar que cargó bien\n",
    "print(\"Shape del DataFrame:\", df.shape)\n",
    "print(\"Primeras columnas:\", df.columns.tolist()[:20])\n",
    "\n",
    "# ==============================================================\n",
    "# 2. DEFINICIÓN DE LA VARIABLE OBJETIVO (REGRESIÓN)\n",
    "# ==============================================================\n",
    "\n",
    "# En el proyecto queremos predecir el \"precio por noche\".\n",
    "# Buscamos el nombre de la columna de target.\n",
    "posibles_targets = [\"price\", \"price_night\", \"price_per_night\"]\n",
    "target_col = None\n",
    "\n",
    "for col in posibles_targets:\n",
    "    if col in df.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\"No se encontró ninguna columna de precio en el DataFrame. \"\n",
    "                     \"Revisa el nombre de la columna de precio y actualiza 'posibles_targets'.\")\n",
    "\n",
    "print(f\"Usaremos la columna '{target_col}' como variable objetivo (y).\")\n",
    "\n",
    "# Si la columna de precio está como texto con símbolos ($, comas), la convertimos a numérico\n",
    "if df[target_col].dtype == \"O\":\n",
    "    df[target_col] = (\n",
    "        df[target_col]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# Nos aseguramos de que no haya valores nulos en la variable objetivo\n",
    "df = df[df[target_col].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a4ba5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables numéricas iniciales: 17\n",
      "Columnas sin variación (se eliminan): 2\n",
      "Dummies casi siempre 0 (se eliminan): 0\n",
      "Dummies casi siempre 1 (se eliminan): 2\n",
      "Variables finales usadas como features: 15\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 3. SELECCIÓN DE VARIABLES PREDICTORAS (X)\n",
    "# ==============================================================\n",
    "\n",
    "# a) Eliminamos columnas identificadoras o claramente no útiles para la red\n",
    "cols_descartar = [\n",
    "    target_col,\n",
    "    \"id\",\n",
    "    \"listing_id\",\n",
    "    \"name\",\n",
    "    \"description\",\n",
    "    \"host_name\",\n",
    "    \"host_id\",\n",
    "    \"last_review\"\n",
    "]\n",
    "\n",
    "# a) Eliminamos columnas identificadoras o claramente no útiles para la red\n",
    "cols_descartar = [\n",
    "    target_col,\n",
    "    \"id\",\n",
    "    \"listing_id\",\n",
    "    \"name\",\n",
    "    \"description\",\n",
    "    \"host_name\",\n",
    "    \"host_id\",\n",
    "    \"last_review\"\n",
    "]\n",
    "\n",
    "cols_descartar = [c for c in cols_descartar if c in df.columns]\n",
    "\n",
    "# Tomamos todas las demás columnas como candidatos\n",
    "X_raw = df.drop(columns=cols_descartar)\n",
    "\n",
    "# b) Nos quedamos solo con variables numéricas (incluye dummies one-hot)\n",
    "X_num = X_raw.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "print(\"Variables numéricas iniciales:\", X_num.shape[1])\n",
    "\n",
    "# --- c) Detectar columnas sin variación (todas las filas tienen el mismo valor) ---\n",
    "cols_sin_variacion = X_num.columns[X_num.nunique() <= 1].tolist()\n",
    "print(\"Columnas sin variación (se eliminan):\", len(cols_sin_variacion))\n",
    "\n",
    "# --- d) Detectar dummies casi siempre 0 o casi siempre 1 ---\n",
    "# Identificamos columnas binarias (solo 0 y 1, ignorando NaN)\n",
    "binary_cols = []\n",
    "for col in X_num.columns:\n",
    "    valores = set(X_num[col].dropna().unique())\n",
    "    if valores.issubset({0, 1}):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "# Calculamos proporción de 1s en cada dummy\n",
    "proporcion_positivos = X_num[binary_cols].mean()\n",
    "\n",
    "# Umbral: menos de 1% de 1s (o más de 99% de 1s)\n",
    "umbral = 0.01\n",
    "cols_casi_todo_cero = proporcion_positivos[proporcion_positivos < umbral].index.tolist()\n",
    "cols_casi_todo_uno = proporcion_positivos[proporcion_positivos > (1 - umbral)].index.tolist()\n",
    "\n",
    "print(\"Dummies casi siempre 0 (se eliminan):\", len(cols_casi_todo_cero))\n",
    "print(\"Dummies casi siempre 1 (se eliminan):\", len(cols_casi_todo_uno))\n",
    "\n",
    "# Lista final de columnas a eliminar por poca información\n",
    "cols_eliminar_por_poca_info = list(set(cols_sin_variacion + cols_casi_todo_cero + cols_casi_todo_uno))\n",
    "\n",
    "# Creamos la matriz final X eliminando esas columnas\n",
    "X = X_num.drop(columns=cols_eliminar_por_poca_info).copy()\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(\"Variables finales usadas como features:\", len(feature_names))\n",
    "\n",
    "# Variable objetivo (serie o vector)\n",
    "y = df[target_col].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cc60260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño X_train: (25952, 15)\n",
      "Tamaño X_val: (6488, 15)\n",
      "Tamaño X_test: (8110, 15)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 4. PARTICIÓN TRAIN / VALIDACIÓN / TEST\n",
    "# ==============================================================\n",
    "\n",
    "# Primero hacemos un split train_val vs test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "# Luego, dentro de train_val, separamos train y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Tamaño X_train:\", X_train.shape)\n",
    "print(\"Tamaño X_val:\", X_val.shape)\n",
    "print(\"Tamaño X_test:\", X_test.shape)\n",
    "\n",
    "# Convertimos a numpy float32 para evitar problemas con Keras\n",
    "X_train_np = X_train.to_numpy().astype(\"float32\")\n",
    "X_val_np   = X_val.to_numpy().astype(\"float32\")\n",
    "X_test_np  = X_test.to_numpy().astype(\"float32\")\n",
    "\n",
    "# ==============================================================\n",
    "# 5. CAPA DE NORMALIZACIÓN PARA LA RED NEURONAL\n",
    "# ==============================================================\n",
    "\n",
    "# Usamos la capa Normalization de Keras\n",
    "normalizer = keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_train_np)   # ahora sí, con numpy\n",
    "\n",
    "input_dim = X_train_np.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a262a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 6. FUNCIÓN PARA CONSTRUIR EL MODELO DE REGRESIÓN\n",
    "# ==============================================================\n",
    "\n",
    "def build_regression_model(\n",
    "    input_dim,\n",
    "    n_layers=2,\n",
    "    n_units=64,\n",
    "    learning_rate=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Construye un modelo de red neuronal para regresión:\n",
    "    - Capa de entrada + capa de normalización\n",
    "    - n_layers capas densas ocultas con activación ReLU\n",
    "    - 1 capa de salida con activación lineal (predicción de precio)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=\"nn_regression_price\")\n",
    "\n",
    "    # Capa de entrada + normalización\n",
    "    model.add(keras.layers.Input(shape=(input_dim,), name=\"input\"))\n",
    "    model.add(normalizer)\n",
    "\n",
    "    # Capas ocultas (no lineales, ReLU)\n",
    "    for i in range(n_layers):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                n_units,\n",
    "                activation=\"relu\",\n",
    "                name=f\"dense_hidden_{i+1}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Capa de salida (lineal) para regresión\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            1,\n",
    "            activation=\"linear\",\n",
    "            name=\"output_price\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Definimos el optimizador Adam con el learning rate dado\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # Compilamos el modelo con loss de MSE y métricas MAE y MSE\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\", \"mse\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91f30f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================\n",
      "Ejecutando combinación #1:\n",
      "  n_layers = 1, n_units = 32, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 119.3699\n",
      "Mejor val_MSE en esta corrida: 1450644.8750\n",
      ">>> ACTUALIZANDO mejor modelo con esta combinación.\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #2:\n",
      "  n_layers = 1, n_units = 32, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 124.8099\n",
      "Mejor val_MSE en esta corrida: 414261.5000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #3:\n",
      "  n_layers = 1, n_units = 32, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 122.3691\n",
      "Mejor val_MSE en esta corrida: 271084.1250\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #4:\n",
      "  n_layers = 1, n_units = 32, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 123.6247\n",
      "Mejor val_MSE en esta corrida: 115201.2031\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #5:\n",
      "  n_layers = 1, n_units = 64, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 131.6048\n",
      "Mejor val_MSE en esta corrida: 6982334.5000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #6:\n",
      "  n_layers = 1, n_units = 64, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 123.9846\n",
      "Mejor val_MSE en esta corrida: 391105.0312\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #7:\n",
      "  n_layers = 1, n_units = 64, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 127.4940\n",
      "Mejor val_MSE en esta corrida: 1085623.8750\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #8:\n",
      "  n_layers = 1, n_units = 64, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 123.0049\n",
      "Mejor val_MSE en esta corrida: 120216.4766\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #9:\n",
      "  n_layers = 1, n_units = 128, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 138.0773\n",
      "Mejor val_MSE en esta corrida: 18823818.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #10:\n",
      "  n_layers = 1, n_units = 128, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 131.8549\n",
      "Mejor val_MSE en esta corrida: 2802518.5000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #11:\n",
      "  n_layers = 1, n_units = 128, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 126.0546\n",
      "Mejor val_MSE en esta corrida: 2219718.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #12:\n",
      "  n_layers = 1, n_units = 128, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 126.2918\n",
      "Mejor val_MSE en esta corrida: 397867.1562\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #13:\n",
      "  n_layers = 2, n_units = 32, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 224.8425\n",
      "Mejor val_MSE en esta corrida: 131332920.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #14:\n",
      "  n_layers = 2, n_units = 32, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 168.1637\n",
      "Mejor val_MSE en esta corrida: 34159044.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #15:\n",
      "  n_layers = 2, n_units = 32, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 147.6368\n",
      "Mejor val_MSE en esta corrida: 25531446.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #16:\n",
      "  n_layers = 2, n_units = 32, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 124.5567\n",
      "Mejor val_MSE en esta corrida: 381928.2812\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #17:\n",
      "  n_layers = 2, n_units = 64, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 206.8316\n",
      "Mejor val_MSE en esta corrida: 111494240.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #18:\n",
      "  n_layers = 2, n_units = 64, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 238.2789\n",
      "Mejor val_MSE en esta corrida: 128482712.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #19:\n",
      "  n_layers = 2, n_units = 64, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 196.4827\n",
      "Mejor val_MSE en esta corrida: 79578768.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #20:\n",
      "  n_layers = 2, n_units = 64, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 162.4781\n",
      "Mejor val_MSE en esta corrida: 27898212.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #21:\n",
      "  n_layers = 2, n_units = 128, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 164.5025\n",
      "Mejor val_MSE en esta corrida: 67989272.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #22:\n",
      "  n_layers = 2, n_units = 128, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 231.1400\n",
      "Mejor val_MSE en esta corrida: 141269952.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #23:\n",
      "  n_layers = 2, n_units = 128, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 225.3014\n",
      "Mejor val_MSE en esta corrida: 132806464.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #24:\n",
      "  n_layers = 2, n_units = 128, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 221.6502\n",
      "Mejor val_MSE en esta corrida: 102897560.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #25:\n",
      "  n_layers = 3, n_units = 32, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 162.0400\n",
      "Mejor val_MSE en esta corrida: 64597704.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #26:\n",
      "  n_layers = 3, n_units = 32, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 241.3446\n",
      "Mejor val_MSE en esta corrida: 154055328.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #27:\n",
      "  n_layers = 3, n_units = 32, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 201.2572\n",
      "Mejor val_MSE en esta corrida: 88297104.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #28:\n",
      "  n_layers = 3, n_units = 32, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 183.9425\n",
      "Mejor val_MSE en esta corrida: 54921472.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #29:\n",
      "  n_layers = 3, n_units = 64, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 100.4040\n",
      "Mejor val_MSE en esta corrida: 21114004.0000\n",
      ">>> ACTUALIZANDO mejor modelo con esta combinación.\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #30:\n",
      "  n_layers = 3, n_units = 64, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 155.5420\n",
      "Mejor val_MSE en esta corrida: 58551468.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #31:\n",
      "  n_layers = 3, n_units = 64, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 195.3395\n",
      "Mejor val_MSE en esta corrida: 98125520.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #32:\n",
      "  n_layers = 3, n_units = 64, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 259.4540\n",
      "Mejor val_MSE en esta corrida: 156795840.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #33:\n",
      "  n_layers = 3, n_units = 128, lr = 0.001, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 93.8665\n",
      "Mejor val_MSE en esta corrida: 18312204.0000\n",
      ">>> ACTUALIZANDO mejor modelo con esta combinación.\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #34:\n",
      "  n_layers = 3, n_units = 128, lr = 0.001, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 135.0525\n",
      "Mejor val_MSE en esta corrida: 42977920.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #35:\n",
      "  n_layers = 3, n_units = 128, lr = 0.0005, batch_size = 64\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 136.1837\n",
      "Mejor val_MSE en esta corrida: 44104420.0000\n",
      "\n",
      "===================================================\n",
      "Ejecutando combinación #36:\n",
      "  n_layers = 3, n_units = 128, lr = 0.0005, batch_size = 128\n",
      "===================================================\n",
      "Mejor val_MAE en esta corrida: 235.4246\n",
      "Mejor val_MSE en esta corrida: 148720784.0000\n",
      "\n",
      "===================================================\n",
      "RESUMEN DE TODAS LAS COMBINACIONES PROBADAS (TOP 10)\n",
      "Ordenado por mejor val_MAE (menor es mejor)\n",
      "===================================================\n",
      "\n",
      "    run_id  n_layers  n_units  learning_rate  batch_size  best_val_mae  \\\n",
      "32      33         3      128         0.0010          64     93.866455   \n",
      "28      29         3       64         0.0010          64    100.403999   \n",
      "0        1         1       32         0.0010          64    119.369896   \n",
      "2        3         1       32         0.0005          64    122.369102   \n",
      "7        8         1       64         0.0005         128    123.004875   \n",
      "3        4         1       32         0.0005         128    123.624710   \n",
      "5        6         1       64         0.0010         128    123.984642   \n",
      "15      16         2       32         0.0005         128    124.556702   \n",
      "1        2         1       32         0.0010         128    124.809929   \n",
      "10      11         1      128         0.0005          64    126.054611   \n",
      "\n",
      "    best_val_mse  \n",
      "32  1.831220e+07  \n",
      "28  2.111400e+07  \n",
      "0   1.450645e+06  \n",
      "2   2.710841e+05  \n",
      "7   1.202165e+05  \n",
      "3   1.152012e+05  \n",
      "5   3.911050e+05  \n",
      "15  3.819283e+05  \n",
      "1   4.142615e+05  \n",
      "10  2.219718e+06  \n",
      "\n",
      "Tabla completa guardada en 'resultados_hiperparametros_regresion_nn.csv'\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 7. BÚSQUEDA DE HIPERPARÁMETROS (GRID PEQUEÑO)\n",
    "# ==============================================================\n",
    "\n",
    "# Listas para la búsqueda (puedes ajustarlas si se demora mucho)\n",
    "n_layers_list = [1, 2, 3]         # número de capas ocultas\n",
    "n_units_list = [32, 64, 128]      # neuronas por capa\n",
    "learning_rates = [1e-3, 5e-4]     # tasas de aprendizaje\n",
    "batch_sizes = [64, 128]           # tamaño de batch\n",
    "max_epochs = 80                   # máximo de épocas\n",
    "\n",
    "# EarlyStopping para evitar sobreentrenamiento\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Variables para guardar el mejor modelo y sus resultados\n",
    "best_model = None\n",
    "best_history = None\n",
    "best_val_mae = np.inf\n",
    "best_params = {}\n",
    "\n",
    "# Si MLflow está disponible, definimos el experimento\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.set_experiment(\"airbnb_regresion_redes_neuronales\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Recorremos todas las combinaciones de hiperparámetros\n",
    "# --------------------------------------------------------------\n",
    "from itertools import product\n",
    "\n",
    "run_id = 0\n",
    "\n",
    "# Lista donde vamos a ir guardando resultados de cada combinación\n",
    "resultados_hp = []   # cada elemento será un diccionario\n",
    "\n",
    "for n_layers, n_units, lr, batch in product(\n",
    "    n_layers_list, n_units_list, learning_rates, batch_sizes\n",
    "):\n",
    "    run_id += 1\n",
    "    print(\"\\n===================================================\")\n",
    "    print(f\"Ejecutando combinación #{run_id}:\")\n",
    "    print(f\"  n_layers = {n_layers}, n_units = {n_units}, \"\n",
    "          f\"lr = {lr}, batch_size = {batch}\")\n",
    "    print(\"===================================================\")\n",
    "\n",
    "    # Creamos el modelo para esta combinación\n",
    "    model = build_regression_model(\n",
    "        input_dim=input_dim,\n",
    "        n_layers=n_layers,\n",
    "        n_units=n_units,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    # Iniciamos run de MLflow si está disponible\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        mlflow.start_run(run_name=f\"reg_nn_run_{run_id}\")\n",
    "        mlflow.log_param(\"model_type\", \"regression_nn\")\n",
    "        mlflow.log_param(\"n_layers\", n_layers)\n",
    "        mlflow.log_param(\"n_units\", n_units)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"batch_size\", batch)\n",
    "\n",
    "    # Entrenamos el modelo\n",
    "    history = model.fit(\n",
    "        X_train_np, y_train,\n",
    "        validation_data=(X_val_np, y_val),\n",
    "        epochs=max_epochs,\n",
    "        batch_size=batch,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Obtenemos el mejor MAE de validación\n",
    "    val_mae_history = history.history[\"val_mae\"]\n",
    "    min_val_mae = float(np.min(val_mae_history))\n",
    "\n",
    "    # También podemos mirar el mejor MSE de validación\n",
    "    val_mse_history = history.history[\"val_mse\"]\n",
    "    min_val_mse = float(np.min(val_mse_history))\n",
    "\n",
    "    print(f\"Mejor val_MAE en esta corrida: {min_val_mae:.4f}\")\n",
    "    print(f\"Mejor val_MSE en esta corrida: {min_val_mse:.4f}\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Guardamos esta combinación y su desempeño en la lista\n",
    "    # ----------------------------------------------------------\n",
    "    resultados_hp.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"n_layers\": n_layers,\n",
    "        \"n_units\": n_units,\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": batch,\n",
    "        \"best_val_mae\": min_val_mae,\n",
    "        \"best_val_mse\": min_val_mse\n",
    "    })\n",
    "\n",
    "    # Loggeamos métricas en MLflow\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        mlflow.log_metric(\"best_val_mae\", min_val_mae)\n",
    "        mlflow.log_metric(\"best_val_mse\", min_val_mse)\n",
    "        # Guardamos el modelo en MLflow\n",
    "        mlflow_keras.log_model(model, artifact_path=\"model\")\n",
    "        mlflow.end_run()\n",
    "\n",
    "    # Actualizamos el mejor modelo si esta corrida es mejor\n",
    "    if min_val_mae < best_val_mae:\n",
    "        best_val_mae = min_val_mae\n",
    "        best_model = model\n",
    "        best_history = history\n",
    "        best_params = {\n",
    "            \"n_layers\": n_layers,\n",
    "            \"n_units\": n_units,\n",
    "            \"learning_rate\": lr,\n",
    "            \"batch_size\": batch\n",
    "        }\n",
    "        print(\">>> ACTUALIZANDO mejor modelo con esta combinación.\")\n",
    "\n",
    "# ==============================================================\n",
    "# 7b. TABLA RESUMEN DE LA BÚSQUEDA DE HIPERPARÁMETROS\n",
    "# ==============================================================\n",
    "\n",
    "df_resultados_hp = pd.DataFrame(resultados_hp)\n",
    "\n",
    "# Ordenamos por mejor val_MAE (menor es mejor)\n",
    "df_resultados_hp = df_resultados_hp.sort_values(\"best_val_mae\", ascending=True)\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\"RESUMEN DE TODAS LAS COMBINACIONES PROBADAS (TOP 10)\")\n",
    "print(\"Ordenado por mejor val_MAE (menor es mejor)\")\n",
    "print(\"===================================================\\n\")\n",
    "\n",
    "print(df_resultados_hp.head(10))\n",
    "\n",
    "# Si quieres, también puedes guardar la tabla completa a CSV\n",
    "df_resultados_hp.to_csv(\"resultados_hiperparametros_regresion_nn.csv\", index=False)\n",
    "print(\"\\nTabla completa guardada en 'resultados_hiperparametros_regresion_nn.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40bd3a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step\n",
      "\n",
      "\n",
      "===================================================\n",
      "RESUMEN DEL MEJOR MODELO DE REGRESIÓN (RED NEURONAL)\n",
      "===================================================\n",
      "\n",
      ">> Hiperparámetros seleccionados:\n",
      "   n_layers: 3\n",
      "   n_units: 128\n",
      "   learning_rate: 0.001\n",
      "   batch_size: 64\n",
      "\n",
      ">> Métricas en VALIDACIÓN (mejor valor durante el entrenamiento):\n",
      "   Mejor val_MAE: 93.8665\n",
      "\n",
      ">> Métricas en TEST (conjunto hold-out):\n",
      "   MAE  (test): 25.3484\n",
      "   MSE  (test): 1345.7728\n",
      "   RMSE (test): 36.6848\n",
      "   R^2  (test): 0.1433\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 8. EVALUACIÓN DEL MEJOR MODELO EN CONJUNTO DE TEST\n",
    "# ==============================================================\n",
    "\n",
    "if best_model is None:\n",
    "    raise RuntimeError(\n",
    "        \"No se entrenó ningún modelo. Revisa la definición de la búsqueda.\"\n",
    "    )\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_test = best_model.predict(X_test_np).flatten()\n",
    "\n",
    "# Cálculo de métricas de desempeño\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_rmse = math.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# ==============================================================\n",
    "# 9. RESUMEN FINAL DEL MEJOR MODELO\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\n\\n===================================================\")\n",
    "print(\"RESUMEN DEL MEJOR MODELO DE REGRESIÓN (RED NEURONAL)\")\n",
    "print(\"===================================================\\n\")\n",
    "\n",
    "print(\">> Hiperparámetros seleccionados:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "\n",
    "print(\"\\n>> Métricas en VALIDACIÓN (mejor valor durante el entrenamiento):\")\n",
    "print(f\"   Mejor val_MAE: {best_val_mae:.4f}\")\n",
    "\n",
    "print(\"\\n>> Métricas en TEST (conjunto hold-out):\")\n",
    "print(f\"   MAE  (test): {test_mae:.4f}\")\n",
    "print(f\"   MSE  (test): {test_mse:.4f}\")\n",
    "print(f\"   RMSE (test): {test_rmse:.4f}\")\n",
    "print(f\"   R^2  (test): {test_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c715015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Arquitectura del modelo (best_model.summary()):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"nn_regression_price\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"nn_regression_price\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_price (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization_6 (\u001b[38;5;33mNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │            \u001b[38;5;34m31\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_3 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_price (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,636</span> (412.65 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,636\u001b[0m (412.65 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,201</span> (137.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,201\u001b[0m (137.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> (128.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m31\u001b[0m (128.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,404</span> (275.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m70,404\u001b[0m (275.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Detalle de capas densas y activaciones:\n",
      "   Capa: dense_hidden_1       | Activación: relu\n",
      "   Capa: dense_hidden_2       | Activación: relu\n",
      "   Capa: dense_hidden_3       | Activación: relu\n",
      "   Capa: output_price         | Activación: linear\n",
      "\n",
      ">> Resumen de capas densas:\n",
      "   Total capas densas: 4\n",
      "   Capas con activación NO lineal (ej. ReLU): 3\n",
      "   Capas con activación lineal (incluye la de salida): 1\n",
      "\n",
      ">> Variables de entrada utilizadas (features):\n",
      "   Número total de variables: 15\n",
      "   Algunas de ellas (primeras 30):\n",
      "    - latitude\n",
      "    - longitude\n",
      "    - accommodates\n",
      "    - beds\n",
      "    - minimum_nights\n",
      "    - maximum_nights\n",
      "    - number_of_reviews\n",
      "    - reviews_per_month\n",
      "    - review_scores_rating\n",
      "    - review_scores_accuracy\n",
      "    - review_scores_cleanliness\n",
      "    - review_scores_checkin\n",
      "    - review_scores_communication\n",
      "    - review_scores_location\n",
      "    - review_scores_value\n",
      "\n",
      "Fin del script de regresión con redes neuronales para Airbnb.\n",
      "Este modelo está pensado para el cliente 'viajeros - clientes frecuentes',\n",
      "ya que permite estimar el precio por noche a partir de múltiples características \n",
      "de la propiedad y del host.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Información sobre arquitectura: capas, activaciones, etc.\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"\\n>> Arquitectura del modelo (best_model.summary()):\\n\")\n",
    "best_model.summary()\n",
    "\n",
    "# Contamos cuántas capas densas lineales y no lineales hay\n",
    "num_dense_layers = 0\n",
    "num_linear_layers = 0\n",
    "num_nonlinear_layers = 0\n",
    "activations = []\n",
    "\n",
    "for layer in best_model.layers:\n",
    "    if isinstance(layer, keras.layers.Dense):\n",
    "        num_dense_layers += 1\n",
    "        act = layer.activation.__name__ if hasattr(layer, \"activation\") else \"none\"\n",
    "        activations.append((layer.name, act))\n",
    "        if act == \"linear\":\n",
    "            num_linear_layers += 1\n",
    "        else:\n",
    "            num_nonlinear_layers += 1\n",
    "\n",
    "print(\"\\n>> Detalle de capas densas y activaciones:\")\n",
    "for name, act in activations:\n",
    "    print(f\"   Capa: {name:20s} | Activación: {act}\")\n",
    "\n",
    "print(\"\\n>> Resumen de capas densas:\")\n",
    "print(f\"   Total capas densas: {num_dense_layers}\")\n",
    "print(f\"   Capas con activación NO lineal (ej. ReLU): {num_nonlinear_layers}\")\n",
    "print(f\"   Capas con activación lineal (incluye la de salida): {num_linear_layers}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Información sobre variables usadas\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"\\n>> Variables de entrada utilizadas (features):\")\n",
    "print(f\"   Número total de variables: {len(feature_names)}\")\n",
    "print(\"   Algunas de ellas (primeras 30):\")\n",
    "for f in feature_names[:30]:\n",
    "    print(\"    -\", f)\n",
    "\n",
    "print(\"\\nFin del script de regresión con redes neuronales para Airbnb.\")\n",
    "print(\"Este modelo está pensado para el cliente 'viajeros - clientes frecuentes',\")\n",
    "print(\"ya que permite estimar el precio por noche a partir de múltiples características \")\n",
    "print(\"de la propiedad y del host.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
