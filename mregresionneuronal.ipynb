{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 0. LIBRERÍAS Y CONFIGURACIÓN INICIAL\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Intentamos importar MLflow (si no está instalado, el código\n",
    "# sigue funcionando pero sin registrar experimentos)\n",
    "# --------------------------------------------------------------\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.keras as mlflow_keras\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Aviso: MLflow no está instalado. \"\n",
    "          \"El código correrá igual, pero sin registrar experimentos.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Fijamos semillas para reproducibilidad básica\n",
    "# --------------------------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 1. CARGA DEL CONJUNTO DE DATOS LIMPIO\n",
    "# ==============================================================\n",
    "\n",
    "# Ruta al archivo limpio (ajusta el nombre si es necesario)\n",
    "DATA_PATH = \"listings_model_no_outliers.csv\"\n",
    "\n",
    "# Leemos el CSV en un DataFrame\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Mostramos información básica para verificar que cargó bien\n",
    "print(\"Shape del DataFrame:\", df.shape)\n",
    "print(\"Primeras columnas:\", df.columns.tolist()[:20])\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 2. DEFINICIÓN DE LA VARIABLE OBJETIVO (REGRESIÓN)\n",
    "# ==============================================================\n",
    "\n",
    "# En el proyecto queremos predecir el \"precio por noche\".\n",
    "# Buscamos el nombre de la columna de target.\n",
    "posibles_targets = [\"price\", \"price_night\", \"price_per_night\"]\n",
    "target_col = None\n",
    "\n",
    "for col in posibles_targets:\n",
    "    if col in df.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\n",
    "        \"No se encontró ninguna columna de precio en el DataFrame. \"\n",
    "        \"Revisa el nombre de la columna de precio y actualiza 'posibles_targets'.\"\n",
    "    )\n",
    "\n",
    "print(f\"Usaremos la columna '{target_col}' como variable objetivo (y).\")\n",
    "\n",
    "# Si la columna de precio está como texto con símbolos ($, comas), la convertimos a numérico\n",
    "if df[target_col].dtype == \"O\":\n",
    "    df[target_col] = (\n",
    "        df[target_col]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# Nos aseguramos de que no haya valores nulos en la variable objetivo\n",
    "df = df[df[target_col].notna()].copy()\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 2b. DEFINICIÓN DE ETIQUETA \"RECOMENDADO\" (PREGUNTA 3)\n",
    "# ==============================================================\n",
    "\n",
    "# Esto deja lista la etiqueta 'recomendado' para que tu compañero\n",
    "# haga el modelo de clasificación (Etapa 4/4b, pregunta 3).\n",
    "\n",
    "# Nos aseguramos de que existan las columnas necesarias\n",
    "cols_necesarias = [\n",
    "    \"review_scores_rating\",\n",
    "    \"review_scores_cleanliness\",\n",
    "    \"number_of_reviews\"\n",
    "]\n",
    "for c in cols_necesarias:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Falta la columna requerida para la regla de recomendación: {c}\"\n",
    "        )\n",
    "\n",
    "# Creamos la columna 'recomendado' basada en la regla:\n",
    "# recomendado = 1 si:\n",
    "#   review_scores_rating       >= 4.0\n",
    "#   y review_scores_cleanliness >= 4.0\n",
    "#   y number_of_reviews        >= 5\n",
    "# recomendado = 0 en caso contrario\n",
    "\n",
    "mask_valid = (\n",
    "    df[\"review_scores_rating\"].notna()\n",
    "    & df[\"review_scores_cleanliness\"].notna()\n",
    "    & df[\"number_of_reviews\"].notna()\n",
    ")\n",
    "\n",
    "df[\"recomendado\"] = 0  # por defecto no recomendado\n",
    "\n",
    "df.loc[\n",
    "    mask_valid\n",
    "    & (df[\"review_scores_rating\"] >= 4.0)\n",
    "    & (df[\"review_scores_cleanliness\"] >= 4.0)\n",
    "    & (df[\"number_of_reviews\"] >= 5),\n",
    "    \"recomendado\"\n",
    "] = 1\n",
    "\n",
    "# Resumen general (para usar en el informe)\n",
    "total_con_info = mask_valid.sum()\n",
    "total_recomendados = df.loc[mask_valid, \"recomendado\"].sum()\n",
    "porc_recomendados = total_recomendados / total_con_info * 100\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\"CLASIFICACIÓN DE LISTINGS: RECOMENDADOS VS NO RECOMENDADOS\")\n",
    "print(\"===================================================\")\n",
    "print(f\"Listings con info suficiente para aplicar la regla: {total_con_info}\")\n",
    "print(f\"Listings recomendados: {total_recomendados} \"\n",
    "      f\"({porc_recomendados:.1f}% de los que tienen info suficiente)\")\n",
    "print(\"La etiqueta 'recomendado' se define por rating >= 4.0, \"\n",
    "      \"limpieza >= 4.0 y al menos 5 reseñas.\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 3. SELECCIÓN DE VARIABLES PREDICTORAS (X)\n",
    "# ==============================================================\n",
    "\n",
    "# a) Eliminamos columnas identificadoras o claramente no útiles para la red\n",
    "cols_descartar = [\n",
    "    target_col,\n",
    "    \"id\",\n",
    "    \"listing_id\",\n",
    "    \"name\",\n",
    "    \"description\",\n",
    "    \"host_name\",\n",
    "    \"host_id\",\n",
    "    \"last_review\",\n",
    "    \"recomendado\",   # esta es para clasificación, no para el precio\n",
    "]\n",
    "\n",
    "cols_descartar = [c for c in cols_descartar if c in df.columns]\n",
    "\n",
    "# Tomamos todas las demás columnas como candidatos\n",
    "X_raw = df.drop(columns=cols_descartar)\n",
    "\n",
    "# b) Convertimos columnas booleanas a 0/1 y luego nos quedamos\n",
    "#    con todas las columnas numéricas (incluye dummies one-hot)\n",
    "bool_cols = X_raw.select_dtypes(include=[\"bool\"]).columns\n",
    "print(\"Columnas booleanas encontradas (se convierten a 0/1):\", len(bool_cols))\n",
    "\n",
    "if len(bool_cols) > 0:\n",
    "    X_raw[bool_cols] = X_raw[bool_cols].astype(int)\n",
    "\n",
    "X_num = X_raw.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "print(\"Variables numéricas iniciales:\", X_num.shape[1])\n",
    "\n",
    "# c) Detectar columnas sin variación (todas las filas tienen el mismo valor)\n",
    "cols_sin_variacion = X_num.columns[X_num.nunique() <= 1].tolist()\n",
    "print(\"Columnas sin variación (se eliminan):\", len(cols_sin_variacion))\n",
    "\n",
    "# d) Detectar dummies casi siempre 0 o casi siempre 1\n",
    "binary_cols = []\n",
    "for col in X_num.columns:\n",
    "    valores = set(X_num[col].dropna().unique())\n",
    "    if valores.issubset({0, 1}):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "# Proporción de 1s en cada dummy\n",
    "proporcion_positivos = X_num[binary_cols].mean()\n",
    "\n",
    "umbral = 0.01\n",
    "cols_casi_todo_cero = proporcion_positivos[proporcion_positivos < umbral].index.tolist()\n",
    "cols_casi_todo_uno = proporcion_positivos[proporcion_positivos > (1 - umbral)].index.tolist()\n",
    "\n",
    "print(\"Dummies casi siempre 0 (se eliminan):\", len(cols_casi_todo_cero))\n",
    "print(\"Dummies casi siempre 1 (se eliminan):\", len(cols_casi_todo_uno))\n",
    "\n",
    "# Lista final de columnas a eliminar por poca información\n",
    "cols_eliminar_por_poca_info = list(\n",
    "    set(cols_sin_variacion + cols_casi_todo_cero + cols_casi_todo_uno)\n",
    ")\n",
    "\n",
    "# Creamos la matriz final X eliminando esas columnas\n",
    "X = X_num.drop(columns=cols_eliminar_por_poca_info).copy()\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(\"Variables finales usadas como features:\", len(feature_names))\n",
    "\n",
    "# Variable objetivo (vector numpy)\n",
    "y = df[target_col].values.astype(\"float32\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 4. PARTICIÓN TRAIN / VALIDACIÓN / TEST\n",
    "# ==============================================================\n",
    "\n",
    "# Primero hacemos un split train_val vs test (80/20)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "# Luego, dentro de train_val, separamos train y validación (80/20)\n",
    "# Resultado final aprox: 64% train, 16% val, 20% test\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Tamaño X_train:\", X_train.shape)\n",
    "print(\"Tamaño X_val:\", X_val.shape)\n",
    "print(\"Tamaño X_test:\", X_test.shape)\n",
    "\n",
    "# Convertimos a numpy float32 para Keras\n",
    "X_train_np = X_train.to_numpy().astype(\"float32\")\n",
    "X_val_np   = X_val.to_numpy().astype(\"float32\")\n",
    "X_test_np  = X_test.to_numpy().astype(\"float32\")\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_val   = y_val.astype(\"float32\")\n",
    "y_test  = y_test.astype(\"float32\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 5. PREPROCESAMIENTO: NORMALIZACIÓN GLOBAL PARA TODAS LAS REDES\n",
    "# ==============================================================\n",
    "\n",
    "input_dim = X_train_np.shape[1]\n",
    "print(\"\\nDimensión de entrada (número de features):\", input_dim)\n",
    "\n",
    "# Creamos UNA capa de normalización, la adaptamos una sola vez\n",
    "normalizer_global = keras.layers.Normalization(axis=-1)\n",
    "normalizer_global.adapt(X_train_np)\n",
    "\n",
    "# Guardamos sus pesos para clonarla en cada modelo sin volver a llamar adapt()\n",
    "normalizer_weights = normalizer_global.get_weights()\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 6. RESUMEN DESCRIPTIVO DEL PRECIO (y)\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\nResumen estadístico del precio (y):\")\n",
    "print(pd.Series(y).describe())\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(y, bins=50)\n",
    "plt.xlabel(\"Precio por noche\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Distribución del precio (antes de modelar)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 7. DEFINICIÓN DE CONFIGURACIONES DE MODELOS (INSPIRADO EN TALLER 5)\n",
    "# ==============================================================\n",
    "\n",
    "def build_model(input_dim, hidden_layers, activation=\"relu\", learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construye un modelo de red neuronal sencilla para regresión de precios.\n",
    "    - input_dim: número de variables de entrada\n",
    "    - hidden_layers: lista con el número de neuronas por capa oculta, ej. [64] o [64, 32]\n",
    "    - activation: 'relu' o 'elu'\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=\"nn_regression_price\")\n",
    "\n",
    "    # Capa de entrada\n",
    "    model.add(keras.layers.Input(shape=(input_dim,)))\n",
    "\n",
    "    # Capa de normalización: clonamos la global y le ponemos los mismos pesos\n",
    "    norm_layer = keras.layers.Normalization(axis=-1, name=\"normalization\")\n",
    "    norm_layer.build((None, input_dim))\n",
    "    norm_layer.set_weights(normalizer_weights)\n",
    "    model.add(norm_layer)\n",
    "\n",
    "    # Capas ocultas\n",
    "    for i, units in enumerate(hidden_layers, start=1):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units,\n",
    "                activation=activation,\n",
    "                name=f\"dense_hidden_{i}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Capa de salida (regresión)\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\", name=\"output\"))\n",
    "\n",
    "    # Compilación: MAE como loss, MAE y MSE como métricas\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7.1 Configuraciones de modelos a probar (búsqueda simple)\n",
    "# --------------------------------------------------------------\n",
    "model_configs = [\n",
    "    {\n",
    "        \"name\": \"base_relu_64\",\n",
    "        \"hidden_layers\": [64],\n",
    "        \"activation\": \"relu\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 128,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"base_elu_64\",\n",
    "        \"hidden_layers\": [64],\n",
    "        \"activation\": \"elu\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 128,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"deep_relu_64_32\",\n",
    "        \"hidden_layers\": [64, 32],\n",
    "        \"activation\": \"relu\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 128,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"deep_elu_64_32\",\n",
    "        \"hidden_layers\": [64, 32],\n",
    "        \"activation\": \"elu\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"batch_size\": 128,\n",
    "    },\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7.2 Entrenamiento de cada configuración + registro en MLflow\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_history = None\n",
    "best_val_mae = np.inf\n",
    "best_params = None\n",
    "\n",
    "for config in model_configs:\n",
    "    name = config[\"name\"]\n",
    "    hidden_layers = config[\"hidden_layers\"]\n",
    "    activation = config[\"activation\"]\n",
    "    lr = config[\"learning_rate\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "\n",
    "    print(\"\\n===================================================\")\n",
    "    print(f\"Ejecutando modelo: {name}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"Capas ocultas: {hidden_layers}\")\n",
    "    print(f\"Activación:    {activation}\")\n",
    "    print(f\"learning_rate: {lr}\")\n",
    "    print(f\"batch_size:    {batch_size}\")\n",
    "\n",
    "    model = build_model(\n",
    "        input_dim=input_dim,\n",
    "        hidden_layers=hidden_layers,\n",
    "        activation=activation,\n",
    "        learning_rate=lr,\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=15,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_np, y_train,\n",
    "        validation_data=(X_val_np, y_val),\n",
    "        epochs=60,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    # Mejor val_mae y val_mse durante el entrenamiento\n",
    "    val_mae = float(np.min(history.history[\"val_mae\"]))\n",
    "    val_mse = float(np.min(history.history[\"val_mse\"]))\n",
    "\n",
    "    # Evaluación en test para comparar entre modelos\n",
    "    y_pred_test_tmp = model.predict(X_test_np).flatten()\n",
    "    test_mae_tmp = mean_absolute_error(y_test, y_pred_test_tmp)\n",
    "    test_mse_tmp = mean_squared_error(y_test, y_pred_test_tmp)\n",
    "    test_r2_tmp = r2_score(y_test, y_pred_test_tmp)\n",
    "\n",
    "    # Registro en MLflow (si está disponible)\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        with mlflow.start_run(run_name=name):\n",
    "            mlflow.log_param(\"hidden_layers\", hidden_layers)\n",
    "            mlflow.log_param(\"activation\", activation)\n",
    "            mlflow.log_param(\"learning_rate\", lr)\n",
    "            mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "            mlflow.log_metric(\"val_mae\", val_mae)\n",
    "            mlflow.log_metric(\"val_mse\", val_mse)\n",
    "            mlflow.log_metric(\"test_mae\", test_mae_tmp)\n",
    "            mlflow.log_metric(\"test_mse\", test_mse_tmp)\n",
    "            mlflow.log_metric(\"test_r2\", test_r2_tmp)\n",
    "\n",
    "            # Opcional: guardar el modelo\n",
    "            # mlflow_keras.log_model(model, \"model\")\n",
    "\n",
    "    # Guardamos resultados en una lista\n",
    "    results.append({\n",
    "        \"model_name\": name,\n",
    "        \"hidden_layers\": hidden_layers,\n",
    "        \"activation\": activation,\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"val_mae\": val_mae,\n",
    "        \"val_mse\": val_mse,\n",
    "        \"test_mae\": test_mae_tmp,\n",
    "        \"test_mse\": test_mse_tmp,\n",
    "        \"test_r2\": test_r2_tmp,\n",
    "    })\n",
    "\n",
    "    # Actualizamos el mejor modelo según val_mae\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        best_model = model\n",
    "        best_history = history\n",
    "        best_params = {\n",
    "            \"model_name\": name,\n",
    "            \"hidden_layers\": hidden_layers,\n",
    "            \"activation\": activation,\n",
    "            \"learning_rate\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "        }\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7.3 Resumen comparativo de modelos\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "df_resultados_modelos = pd.DataFrame(results)\n",
    "df_resultados_modelos = df_resultados_modelos.sort_values(\"val_mae\").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\"RESUMEN DE MODELOS (ordenados por val_mae)\")\n",
    "print(\"===================================================\\n\")\n",
    "print(df_resultados_modelos)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 8. EVALUACIÓN DEL MEJOR MODELO EN CONJUNTO DE TEST\n",
    "# ==============================================================\n",
    "\n",
    "if best_model is None:\n",
    "    raise RuntimeError(\"No se entrenó ningún modelo. Revisa la definición de la búsqueda.\")\n",
    "\n",
    "# Predicciones en el conjunto de prueba (sin restricciones)\n",
    "y_pred_test_raw = best_model.predict(X_test_np).flatten()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Recorte a un mínimo razonable (precio no negativo)\n",
    "# --------------------------------------------------------------\n",
    "min_price = 0.0  # si quieres, podrías usar y.min() en vez de 0.0\n",
    "y_pred_test = np.maximum(y_pred_test_raw, min_price)\n",
    "\n",
    "# Cálculo de métricas de desempeño usando las predicciones recortadas\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_rmse = math.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8a. BASELINE: predecir siempre la media del precio de train\n",
    "# --------------------------------------------------------------\n",
    "media_train = float(y_train.mean())\n",
    "baseline_pred = np.full_like(y_test, fill_value=media_train, dtype=float)\n",
    "\n",
    "baseline_mae = mean_absolute_error(y_test, baseline_pred)\n",
    "baseline_mse = mean_squared_error(y_test, baseline_pred)\n",
    "\n",
    "mejora_relativa_mae = (1 - test_mae / baseline_mae) * 100\n",
    "\n",
    "print(\"\\n====== Comparación con baseline ======\")\n",
    "print(f\"Media precio train: {media_train:.4f}\")\n",
    "print(f\"MAE baseline (media de train):      {baseline_mae:.4f}\")\n",
    "print(f\"MSE baseline (media de train):      {baseline_mse:.4f}\")\n",
    "print(f\"MAE red neuronal (mejor modelo):    {test_mae:.4f}\")\n",
    "print(f\"MSE red neuronal (mejor modelo):    {test_mse:.4f}\")\n",
    "print(f\"Mejora relativa vs baseline (MAE):  {mejora_relativa_mae:.2f}%\")\n",
    "print(\"======================================\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 8b. GRÁFICOS: PRECIO REAL vs PRECIO PREDICHO \n",
    "# ==============================================================\n",
    "\n",
    "df_pred_vs_real = pd.DataFrame({\n",
    "    \"precio_real\": y_test,\n",
    "    \"precio_predicho\": y_pred_test\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# 8b.1 Serie en el orden original\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_pred_vs_real[\"precio_real\"].values, label=\"Precio real\")\n",
    "plt.plot(df_pred_vs_real[\"precio_predicho\"].values, label=\"Precio predicho\", alpha=0.8)\n",
    "plt.xlabel(\"Observación en test\")\n",
    "plt.ylabel(\"Precio\")\n",
    "plt.title(\"Precio real vs precio predicho - Conjunto de test (orden original)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(\"precio_real_vs_predicho_serie_test.png\", dpi=300)\n",
    "\n",
    "# 8b.3 Scatter real vs predicho con línea ideal\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(df_pred_vs_real[\"precio_real\"],\n",
    "            df_pred_vs_real[\"precio_predicho\"],\n",
    "            s=5, alpha=0.4)\n",
    "max_price = df_pred_vs_real[\"precio_real\"].max()\n",
    "plt.plot([0, max_price], [0, max_price], linestyle=\"--\")\n",
    "plt.xlabel(\"Precio real\")\n",
    "plt.ylabel(\"Precio predicho\")\n",
    "plt.title(\"Dispersión precio real vs predicho (conjunto de test)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(\"precio_real_vs_predicho_scatter_test.png\", dpi=300)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 8d. FUNCIÓN PARA EJEMPLO DE PREDICCIÓN (PREGUNTA 1)\n",
    "# ==============================================================\n",
    "\n",
    "def mostrar_prediccion_ejemplo(idx=0):\n",
    "    \"\"\"\n",
    "    Muestra el precio real y predicho para un ejemplo del conjunto de test.\n",
    "    Esto ayuda a responder:\n",
    "    'Dado un determinado departamento, ¿cuál será el precio más adecuado por noche?'\n",
    "    \"\"\"\n",
    "    x_sample = X_test_np[idx:idx+1]\n",
    "    y_real = float(y_test[idx])\n",
    "\n",
    "    # Predicción cruda del modelo\n",
    "    y_pred_raw = float(best_model.predict(x_sample).flatten()[0])\n",
    "    # Recorte a mínimo 0 para mostrar algo con sentido económico\n",
    "    y_pred = max(y_pred_raw, 0.0)\n",
    "\n",
    "    print(\"\\nEjemplo de predicción para un departamento del conjunto de test\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f\"Índice interno en X_test: {idx}\")\n",
    "    print(f\"Precio real        : {y_real:.2f}\")\n",
    "    print(f\"Precio predicho    : {y_pred:.2f}\")\n",
    "    print(f\"Predicción (cruda) : {y_pred_raw:.2f}\")\n",
    "    print(f\"Error absoluto     : {abs(y_real - y_pred):.2f}\")\n",
    "\n",
    "\n",
    "# Llamada de ejemplo (puedes cambiar el índice):\n",
    "# mostrar_prediccion_ejemplo(idx=0)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 8e. ANÁLISIS DE CORRELACIONES PARA RECOMENDACIONES (PREGUNTA 2)\n",
    "# ==============================================================\n",
    "\n",
    "# Unimos X y y para calcular correlaciones simples con el precio\n",
    "y_full_series = pd.Series(y, name=target_col)\n",
    "df_corr = pd.concat(\n",
    "    [X.reset_index(drop=True), y_full_series.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "corr_with_price = df_corr.corr()[target_col].drop(target_col).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\"CORRELACIONES DE FEATURES CON EL PRECIO\")\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(\"\\nTop 10 variables con correlación POSITIVA con el precio:\")\n",
    "for feat, val in corr_with_price.head(10).items():\n",
    "    print(f\"  {feat:30s} -> corr = {val:.3f}\")\n",
    "\n",
    "print(\"\\nTop 10 variables con correlación NEGATIVA con el precio:\")\n",
    "for feat, val in corr_with_price.tail(10).items():\n",
    "    print(f\"  {feat:30s} -> corr = {val:.3f}\")\n",
    "\n",
    "\n",
    "def imprimir_recomendaciones_basadas_en_correlaciones(top_k=5):\n",
    "    \"\"\"\n",
    "    Genera recomendaciones textuales a partir de las correlaciones con el precio.\n",
    "    Esto sirve como base para responder:\n",
    "    '¿Qué consejos les podemos dar a los anfitriones para incrementar el precio...?'\n",
    "    \"\"\"\n",
    "    print(\"\\n===================================================\")\n",
    "    print(\"Sugerencias para anfitriones basadas en correlaciones simples\")\n",
    "    print(\"===================================================\\n\")\n",
    "\n",
    "    print(f\"Variables más asociadas a precios ALTOS (top {top_k}):\")\n",
    "    for feat, val in corr_with_price.head(top_k).items():\n",
    "        print(f\"- {feat} (corr ≈ {val:.2f}): mantener o reforzar esta característica.\")\n",
    "\n",
    "    print(f\"\\nVariables más asociadas a precios BAJOS (bottom {top_k}):\")\n",
    "    for feat, val in corr_with_price.tail(top_k).items():\n",
    "        print(f\"- {feat} (corr ≈ {val:.2f}): revisar si es posible mejorarla o compensarla.\")\n",
    "\n",
    "    print(\"\\nEn el informe puedes traducir estas correlaciones en consejos concretos,\")\n",
    "    print(\"por ejemplo, destacar tipos de propiedad, barrios o características que\")\n",
    "    print(\"el modelo asocia con precios más altos.\\n\")\n",
    "\n",
    "# Llamada de ejemplo:\n",
    "# imprimir_recomendaciones_basadas_en_correlaciones(top_k=5)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 9. GRÁFICO DE LA ARQUITECTURA DEL MEJOR MODELO\n",
    "# ==============================================================\n",
    "\n",
    "try:\n",
    "    keras.utils.plot_model(\n",
    "        best_model,\n",
    "        to_file=\"arquitectura_mejor_modelo.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        expand_nested=True\n",
    "    )\n",
    "    print(\"\\nDiagrama de arquitectura guardado en 'arquitectura_mejor_modelo.png'.\")\n",
    "    print(\"Revisa este archivo PNG para incluirlo en tu reporte.\")\n",
    "except Exception as e:\n",
    "    print(\"\\nNo se pudo graficar la arquitectura del modelo.\")\n",
    "    print(\"Posibles causas: falta de graphviz/pydot. Error original:\")\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 10. RESUMEN FINAL DEL MEJOR MODELO DE REGRESIÓN\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\n\\n===================================================\")\n",
    "print(\"RESUMEN DEL MEJOR MODELO DE REGRESIÓN (RED NEURONAL)\")\n",
    "print(\"===================================================\\n\")\n",
    "\n",
    "print(\">> Configuración seleccionada:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "\n",
    "print(\"\\n>> Métricas en VALIDACIÓN (mejor valor durante el entrenamiento):\")\n",
    "print(f\"   Mejor val_MAE: {best_val_mae:.4f}\")\n",
    "\n",
    "print(\"\\n>> Métricas en TEST (conjunto hold-out):\")\n",
    "print(f\"   MAE  (test): {test_mae:.4f}\")\n",
    "print(f\"   MSE  (test): {test_mse:.4f}\")\n",
    "print(f\"   RMSE (test): {test_rmse:.4f}\")\n",
    "print(f\"   R^2  (test): {test_r2:.4f}\")\n",
    "\n",
    "print(\"\\n>> Comparación con baseline (predecir siempre la media de train):\")\n",
    "print(f\"   MAE baseline: {baseline_mae:.4f}\")\n",
    "print(f\"   Mejora relativa MAE vs baseline: {mejora_relativa_mae:.2f}%\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Información sobre arquitectura: capas, activaciones, etc.\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"\\n>> Arquitectura del modelo (best_model.summary()):\\n\")\n",
    "best_model.summary()\n",
    "\n",
    "# Contamos cuántas capas densas lineales y no lineales hay\n",
    "num_dense_layers = 0\n",
    "num_linear_layers = 0\n",
    "num_nonlinear_layers = 0\n",
    "activations_info = []\n",
    "\n",
    "for layer in best_model.layers:\n",
    "    if isinstance(layer, keras.layers.Dense):\n",
    "        num_dense_layers += 1\n",
    "        act = layer.activation.__name__ if hasattr(layer, \"activation\") else \"none\"\n",
    "        activations_info.append((layer.name, act))\n",
    "        if act == \"linear\":\n",
    "            num_linear_layers += 1\n",
    "        else:\n",
    "            num_nonlinear_layers += 1\n",
    "\n",
    "print(\"\\n>> Detalle de capas densas y activaciones:\")\n",
    "for name, act in activations_info:\n",
    "    print(f\"   Capa: {name:20s} | Activación: {act}\")\n",
    "\n",
    "print(\"\\n>> Resumen de capas densas:\")\n",
    "print(f\"   Total capas densas: {num_dense_layers}\")\n",
    "print(f\"   Capas con activación NO lineal (ReLU/ELU): {num_nonlinear_layers}\")\n",
    "print(f\"   Capas con activación lineal (incluye la de salida): {num_linear_layers}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Información sobre variables usadas\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"\\n>> Variables de entrada utilizadas (features):\")\n",
    "print(f\"   Número total de variables: {len(feature_names)}\")\n",
    "print(\"   Algunas de ellas (primeras 30):\")\n",
    "for f in feature_names[:30]:\n",
    "    print(\"    -\", f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
