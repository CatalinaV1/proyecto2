{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 0. LIBRERAS Y CONFIGURACIN INICIAL\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Intentamos importar MLflow (si no est谩 instalado, el c贸digo\n",
    "# sigue funcionando pero sin registrar experimentos)\n",
    "# --------------------------------------------------------------\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.keras as mlflow_keras\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"Aviso: MLflow no est谩 instalado. \"\n",
    "          \"El c贸digo correr谩 igual, pero sin registrar experimentos.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Fijamos semillas para reproducibilidad b谩sica\n",
    "# --------------------------------------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ==============================================================\n",
    "# 1. CARGA DEL CONJUNTO DE DATOS LIMPIO\n",
    "# ==============================================================\n",
    "\n",
    "# Ruta al archivo limpio (ajusta el nombre si es necesario)\n",
    "DATA_PATH = \"listings_model_no_outliers.csv\"\n",
    "\n",
    "# Leemos el CSV en un DataFrame\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Mostramos informaci贸n b谩sica para verificar que carg贸 bien\n",
    "print(\"Shape del DataFrame:\", df.shape)\n",
    "print(\"Primeras columnas:\", df.columns.tolist()[:20])\n",
    "\n",
    "# ==============================================================\n",
    "# 2. DEFINICIN DE LA VARIABLE OBJETIVO (REGRESIN)\n",
    "# ==============================================================\n",
    "\n",
    "# En el proyecto queremos predecir el \"precio por noche\".\n",
    "# Buscamos el nombre de la columna de target.\n",
    "posibles_targets = [\"price\", \"price_night\", \"price_per_night\"]\n",
    "target_col = None\n",
    "\n",
    "for col in posibles_targets:\n",
    "    if col in df.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\n",
    "        \"No se encontr贸 ninguna columna de precio en el DataFrame. \"\n",
    "        \"Revisa el nombre de la columna de precio y actualiza 'posibles_targets'.\"\n",
    "    )\n",
    "\n",
    "print(f\"Usaremos la columna '{target_col}' como variable objetivo (y).\")\n",
    "\n",
    "# Si la columna de precio est谩 como texto con s铆mbolos ($, comas), la convertimos a num茅rico\n",
    "if df[target_col].dtype == \"O\":\n",
    "    df[target_col] = (\n",
    "        df[target_col]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[\\$,]\", \"\", regex=True)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# Nos aseguramos de que no haya valores nulos en la variable objetivo\n",
    "df = df[df[target_col].notna()].copy()\n",
    "\n",
    "# ==============================================================\n",
    "# 2b. DEFINICIN DE ETIQUETA \"RECOMENDADO\" (PREGUNTA 3)\n",
    "# ==============================================================\n",
    "\n",
    "# Nos aseguramos de que existan las columnas necesarias\n",
    "cols_necesarias = [\n",
    "    \"review_scores_rating\",\n",
    "    \"review_scores_cleanliness\",\n",
    "    \"number_of_reviews\"\n",
    "]\n",
    "for c in cols_necesarias:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Falta la columna requerida para la regla de recomendaci贸n: {c}\"\n",
    "        )\n",
    "\n",
    "# Creamos la columna 'recomendado' basada en la regla:\n",
    "# recomendado = 1 si:\n",
    "#   review_scores_rating       >= 4.0\n",
    "#   y review_scores_cleanliness >= 4.0\n",
    "#   y number_of_reviews        >= 5\n",
    "# recomendado = 0 en caso contrario\n",
    "\n",
    "mask_valid = (\n",
    "    df[\"review_scores_rating\"].notna()\n",
    "    & df[\"review_scores_cleanliness\"].notna()\n",
    "    & df[\"number_of_reviews\"].notna()\n",
    ")\n",
    "\n",
    "df[\"recomendado\"] = 0  # por defecto no recomendado\n",
    "\n",
    "df.loc[\n",
    "    mask_valid\n",
    "    & (df[\"review_scores_rating\"] >= 4.0)\n",
    "    & (df[\"review_scores_cleanliness\"] >= 4.0)\n",
    "    & (df[\"number_of_reviews\"] >= 5),\n",
    "    \"recomendado\"\n",
    "] = 1\n",
    "\n",
    "# Resumen general (para usar en el informe)\n",
    "total_con_info = mask_valid.sum()\n",
    "total_recomendados = df.loc[mask_valid, \"recomendado\"].sum()\n",
    "porc_recomendados = total_recomendados / total_con_info * 100\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\"CLASIFICACIN DE LISTINGS: RECOMENDADOS VS NO RECOMENDADOS\")\n",
    "print(\"===================================================\")\n",
    "print(f\"Listings con info suficiente para aplicar la regla: {total_con_info}\")\n",
    "print(f\"Listings recomendados: {total_recomendados} \"\n",
    "      f\"({porc_recomendados:.1f}% de los que tienen info suficiente)\")\n",
    "print(\"La etiqueta 'recomendado' se define por rating >= 4.0, \"\n",
    "      \"limpieza >= 4.0 y al menos 5 rese帽as.\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 3. SELECCIN DE VARIABLES PREDICTORAS (X)\n",
    "# ==============================================================\n",
    "\n",
    "# a) Eliminamos columnas identificadoras o claramente no 煤tiles para la red\n",
    "cols_descartar = [\n",
    "    target_col,\n",
    "    \"id\",\n",
    "    \"listing_id\",\n",
    "    \"name\",\n",
    "    \"description\",\n",
    "    \"host_name\",\n",
    "    \"host_id\",\n",
    "    \"last_review\",\n",
    "    \"recomendado\",   \n",
    "]\n",
    "\n",
    "\n",
    "cols_descartar = [c for c in cols_descartar if c in df.columns]\n",
    "\n",
    "# Tomamos todas las dem谩s columnas como candidatos\n",
    "X_raw = df.drop(columns=cols_descartar)\n",
    "\n",
    "# b) Convertimos columnas booleanas a 0/1 y luego nos quedamos\n",
    "#    con todas las columnas num茅ricas (incluye dummies one-hot)\n",
    "bool_cols = X_raw.select_dtypes(include=[\"bool\"]).columns\n",
    "print(\"Columnas booleanas encontradas (se convierten a 0/1):\", len(bool_cols))\n",
    "\n",
    "if len(bool_cols) > 0:\n",
    "    X_raw[bool_cols] = X_raw[bool_cols].astype(int)\n",
    "\n",
    "X_num = X_raw.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "print(\"Variables num茅ricas iniciales:\", X_num.shape[1])\n",
    "\n",
    "\n",
    "# --- c) Detectar columnas sin variaci贸n (todas las filas tienen el mismo valor) ---\n",
    "cols_sin_variacion = X_num.columns[X_num.nunique() <= 1].tolist()\n",
    "print(\"Columnas sin variaci贸n (se eliminan):\", len(cols_sin_variacion))\n",
    "\n",
    "# --- d) Detectar dummies casi siempre 0 o casi siempre 1 ---\n",
    "# Identificamos columnas binarias (solo 0 y 1, ignorando NaN)\n",
    "binary_cols = []\n",
    "for col in X_num.columns:\n",
    "    valores = set(X_num[col].dropna().unique())\n",
    "    if valores.issubset({0, 1}):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "# Calculamos proporci贸n de 1s en cada dummy\n",
    "proporcion_positivos = X_num[binary_cols].mean()\n",
    "\n",
    "# Umbral: menos de 1% de 1s (o m谩s de 99% de 1s)\n",
    "umbral = 0.01\n",
    "cols_casi_todo_cero = proporcion_positivos[proporcion_positivos < umbral].index.tolist()\n",
    "cols_casi_todo_uno = proporcion_positivos[proporcion_positivos > (1 - umbral)].index.tolist()\n",
    "\n",
    "print(\"Dummies casi siempre 0 (se eliminan):\", len(cols_casi_todo_cero))\n",
    "print(\"Dummies casi siempre 1 (se eliminan):\", len(cols_casi_todo_uno))\n",
    "\n",
    "# Lista final de columnas a eliminar por poca informaci贸n\n",
    "cols_eliminar_por_poca_info = list(\n",
    "    set(cols_sin_variacion + cols_casi_todo_cero + cols_casi_todo_uno)\n",
    ")\n",
    "\n",
    "# Creamos la matriz final X eliminando esas columnas\n",
    "X = X_num.drop(columns=cols_eliminar_por_poca_info).copy()\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(\"Variables finales usadas como features:\", len(feature_names))\n",
    "\n",
    "# Variable objetivo (serie o vector)\n",
    "y = df[target_col].values\n",
    "\n",
    "# ==============================================================\n",
    "# 4. PARTICIN TRAIN / VALIDACIN / TEST\n",
    "# ==============================================================\n",
    "\n",
    "# Primero hacemos un split train_val vs test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "# Luego, dentro de train_val, separamos train y validaci贸n\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Tama帽o X_train:\", X_train.shape)\n",
    "print(\"Tama帽o X_val:\", X_val.shape)\n",
    "print(\"Tama帽o X_test:\", X_test.shape)\n",
    "\n",
    "# Convertimos a numpy float32 para evitar problemas con Keras\n",
    "X_train_np = X_train.to_numpy().astype(\"float32\")\n",
    "X_val_np   = X_val.to_numpy().astype(\"float32\")\n",
    "X_test_np  = X_test.to_numpy().astype(\"float32\")\n",
    "\n",
    "# ==============================================================\n",
    "# 5. CAPA DE NORMALIZACIN PARA LA RED NEURONAL\n",
    "# ==============================================================\n",
    "\n",
    "# Usamos la capa Normalization de Keras\n",
    "normalizer = keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_train_np)   # ahora s铆, con numpy\n",
    "\n",
    "input_dim = X_train_np.shape[1]\n",
    "\n",
    "# ==============================================================\n",
    "# 6. FUNCIN PARA CONSTRUIR EL MODELO DE REGRESIN\n",
    "# ==============================================================\n",
    "\n",
    "def build_regression_model(\n",
    "    input_dim,\n",
    "    n_layers=2,\n",
    "    n_units=64,\n",
    "    learning_rate=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Construye un modelo de red neuronal para regresi贸n:\n",
    "    - Capa de entrada + capa de normalizaci贸n\n",
    "    - n_layers capas densas ocultas con activaci贸n ReLU\n",
    "    - 1 capa de salida con activaci贸n lineal (predicci贸n de precio)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=\"nn_regression_price\")\n",
    "\n",
    "    # Capa de entrada + normalizaci贸n\n",
    "    model.add(keras.layers.Input(shape=(input_dim,), name=\"input\"))\n",
    "    model.add(normalizer)\n",
    "\n",
    "    # Capas ocultas (no lineales, ReLU)\n",
    "    for i in range(n_layers):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                n_units,\n",
    "                activation=\"relu\",\n",
    "                name=f\"dense_hidden_{i+1}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Capa de salida (lineal) para regresi贸n\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            1,\n",
    "            activation=\"linear\",\n",
    "            name=\"output_price\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Definimos el optimizador Adam con el learning rate dado\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # Compilamos el modelo con loss de MSE y m茅tricas MAE y MSE\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\", \"mse\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==============================================================\n",
    "# 7. BSQUEDA DE HIPERPARMETROS (GRID PEQUEO)\n",
    "# ==============================================================\n",
    "\n",
    "# Listas para la b煤squeda (puedes ajustarlas si se demora mucho)\n",
    "n_layers_list = [1, 2, 3]         # n煤mero de capas ocultas\n",
    "n_units_list = [32, 64, 128]      # neuronas por capa\n",
    "learning_rates = [1e-3, 5e-4]     # tasas de aprendizaje\n",
    "batch_sizes = [64, 128]           # tama帽o de batch\n",
    "max_epochs = 80                   # m谩ximo de 茅pocas\n",
    "\n",
    "# EarlyStopping para evitar sobreentrenamiento\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Variables para guardar el mejor modelo y sus resultados\n",
    "best_model = None\n",
    "best_history = None\n",
    "best_val_mae = np.inf\n",
    "best_params = {}\n",
    "\n",
    "# Si MLflow est谩 disponible, definimos el experimento\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.set_experiment(\"airbnb_regresion_redes_neuronales\")\n",
    "# --------------------------------------------------------------\n",
    "# Recorremos todas las combinaciones de hiperpar谩metros\n",
    "# --------------------------------------------------------------\n",
    "from itertools import product\n",
    "\n",
    "run_id = 0\n",
    "\n",
    "# Lista donde vamos a ir guardando resultados de cada combinaci贸n\n",
    "resultados_hp = []   # cada elemento ser谩 un diccionario\n",
    "\n",
    "for n_layers, n_units, lr, batch in product(\n",
    "    n_layers_list, n_units_list, learning_rates, batch_sizes\n",
    "):\n",
    "    run_id += 1\n",
    "    print(\"\\n===================================================\")\n",
    "    print(f\"Ejecutando combinaci贸n #{run_id}:\")\n",
    "    print(f\"  n_layers = {n_layers}, n_units = {n_units}, \"\n",
    "          f\"lr = {lr}, batch_size = {batch}\")\n",
    "    print(\"===================================================\")\n",
    "\n",
    "    # Creamos el modelo\n",
    "    model = build_regression_model(\n",
    "        input_dim=input_dim,\n",
    "        n_layers=n_layers,\n",
    "        n_units=n_units,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    # Iniciamos run de MLflow si est谩 disponible\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        #  NUEVO: cerrar cualquier run activo antes de abrir uno nuevo\n",
    "        active_run = mlflow.active_run()\n",
    "        if active_run is not None:\n",
    "            mlflow.end_run()\n",
    "\n",
    "        mlflow.start_run(run_name=f\"reg_nn_run_{run_id}\")\n",
    "        mlflow.log_param(\"model_type\", \"regression_nn\")\n",
    "        mlflow.log_param(\"n_layers\", n_layers)\n",
    "        mlflow.log_param(\"n_units\", n_units)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"batch_size\", batch)\n",
    "\n",
    "    # Entrenamos el modelo\n",
    "    history = model.fit(\n",
    "        X_train_np, y_train,\n",
    "        validation_data=(X_val_np, y_val),\n",
    "        epochs=max_epochs,\n",
    "        batch_size=batch,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Obtenemos el mejor MAE de validaci贸n\n",
    "    val_mae_history = history.history[\"val_mae\"]\n",
    "    min_val_mae = float(np.min(val_mae_history))\n",
    "\n",
    "    # Tambi茅n podemos mirar el mejor MSE de validaci贸n\n",
    "    val_mse_history = history.history[\"val_mse\"]\n",
    "    min_val_mse = float(np.min(val_mse_history))\n",
    "\n",
    "    print(f\"Mejor val_MAE en esta corrida: {min_val_mae:.4f}\")\n",
    "    print(f\"Mejor val_MSE en esta corrida: {min_val_mse:.4f}\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Guardamos esta combinaci贸n y su desempe帽o en la lista\n",
    "    # ----------------------------------------------------------\n",
    "    resultados_hp.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"n_layers\": n_layers,\n",
    "        \"n_units\": n_units,\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": batch,\n",
    "        \"best_val_mae\": min_val_mae,\n",
    "        \"best_val_mse\": min_val_mse\n",
    "    })\n",
    "\n",
    "    # Loggeamos m茅tricas y modelo en MLflow (versi贸n simple, robusta)\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        mlflow.log_metric(\"best_val_mae\", min_val_mae)\n",
    "        mlflow.log_metric(\"best_val_mse\", min_val_mse)\n",
    "        mlflow_keras.log_model(model, artifact_path=\"model\")\n",
    "        mlflow.end_run()\n",
    "\n",
    "    # Actualizamos el mejor modelo si esta corrida es mejor\n",
    "    if min_val_mae < best_val_mae:\n",
    "        best_val_mae = min_val_mae\n",
    "        best_model = model\n",
    "        best_history = history\n",
    "        best_params = {\n",
    "            \"n_layers\": n_layers,\n",
    "            \"n_units\": n_units,\n",
    "            \"learning_rate\": lr,\n",
    "            \"batch_size\": batch\n",
    "        }\n",
    "        print(\">>> ACTUALIZANDO mejor modelo con esta combinaci贸n.\")\n",
    "\n",
    "# ==============================================================\n",
    "# 7b. TABLA RESUMEN DE LA BSQUEDA DE HIPERPARMETROS\n",
    "# ==============================================================\n",
    "\n",
    "df_resultados_hp = pd.DataFrame(resultados_hp)\n",
    "\n",
    "# Ordenamos por mejor val_MAE (menor es mejor)\n",
    "df_resultados_hp = df_resultados_hp.sort_values(\"best_val_mae\", ascending=True)\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\"RESUMEN DE TODAS LAS COMBINACIONES PROBADAS (TOP 10)\")\n",
    "print(\"Ordenado por mejor val_MAE (menor es mejor)\")\n",
    "print(\"===================================================\\n\")\n",
    "\n",
    "print(df_resultados_hp.head(10))\n",
    "\n",
    "# Si quieres, tambi茅n puedes guardar la tabla completa a CSV\n",
    "df_resultados_hp.to_csv(\"resultados_hiperparametros_regresion_nn.csv\", index=False)\n",
    "print(\"\\nTabla completa guardada en 'resultados_hiperparametros_regresion_nn.csv'\")\n",
    "\n",
    "# ==============================================================\n",
    "# 8. EVALUACIN DEL MEJOR MODELO EN CONJUNTO DE TEST\n",
    "# ==============================================================\n",
    "\n",
    "if best_model is None:\n",
    "    raise RuntimeError(\n",
    "        \"No se entren贸 ning煤n modelo. Revisa la definici贸n de la b煤squeda.\"\n",
    "    )\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred_test = best_model.predict(X_test_np).flatten()\n",
    "\n",
    "# C谩lculo de m茅tricas de desempe帽o\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_rmse = math.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# ==============================================================\n",
    "# 8b. GRFICO: PRECIO REAL vs PRECIO PREDICHO (SERIE)\n",
    "# ==============================================================\n",
    "\n",
    "df_pred_vs_real = pd.DataFrame({\n",
    "    \"precio_real\": y_test,\n",
    "    \"precio_predicho\": y_pred_test\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_pred_vs_real[\"precio_real\"].values, label=\"Precio real\")\n",
    "plt.plot(df_pred_vs_real[\"precio_predicho\"].values, label=\"Precio predicho\", alpha=0.8)\n",
    "plt.xlabel(\"Observaci贸n en test\")\n",
    "plt.ylabel(\"Precio\")\n",
    "plt.title(\"Precio real vs precio predicho - Conjunto de test (serie)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(\"precio_real_vs_predicho_serie_test.png\", dpi=300)\n",
    "\n",
    "# ==============================================================\n",
    "# 8c. GRFICO: PRECIO REAL vs PRECIO PREDICHO (SCATTER 45掳)\n",
    "# ==============================================================\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.axes(aspect='equal')\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "plt.xlabel(\"Precio real\")\n",
    "plt.ylabel(\"Precio predicho\")\n",
    "min_val = min(y_test.min(), y_pred_test.min())\n",
    "max_val = max(y_test.max(), y_pred_test.max())\n",
    "lims = [min_val, max_val]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.plot(lims, lims, linestyle=\"--\")\n",
    "plt.title(\"Dispersi贸n precio real vs predicho - Conjunto de test\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(\"precio_real_vs_predicho_scatter_test.png\", dpi=300)\n",
    "\n",
    "# ==============================================================\n",
    "# 8d. HISTORIAL DE PRDIDA Y MAE DEL MEJOR MODELO\n",
    "# ==============================================================\n",
    "\n",
    "if best_history is not None:\n",
    "    history_dict = best_history.history\n",
    "\n",
    "    # Historial de p茅rdida (loss)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history_dict[\"loss\"], label=\"P茅rdida entrenamiento\")\n",
    "    plt.plot(history_dict[\"val_loss\"], label=\"P茅rdida validaci贸n\")\n",
    "    plt.xlabel(\"poca\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.title(\"Historial de p茅rdida - Mejor modelo\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(\"historial_perdida_mejor_modelo.png\", dpi=300)\n",
    "\n",
    "    # Historial de MAE\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history_dict[\"mae\"], label=\"MAE entrenamiento\")\n",
    "    plt.plot(history_dict[\"val_mae\"], label=\"MAE validaci贸n\")\n",
    "    plt.xlabel(\"poca\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"Historial de MAE - Mejor modelo\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(\"historial_mae_mejor_modelo.png\", dpi=300)\n",
    "\n",
    "else:\n",
    "    print(\"No se guard贸 el history del mejor modelo, \"\n",
    "          \"no se puede graficar el historial de p茅rdida/MAE.\")\n",
    "\n",
    "# ==============================================================\n",
    "# 8e. ANLISIS DE CORRELACIONES PARA GENERAR RECOMENDACIONES\n",
    "# ==============================================================\n",
    "\n",
    "# Unimos X y y para calcular correlaciones simples con el precio\n",
    "df_corr = pd.concat(\n",
    "    [X.reset_index(drop=True), pd.Series(y, name=target_col).reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "corr_with_price = df_corr.corr()[target_col].drop(target_col).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n===================================================\")\n",
    "print(\"CORRELACIONES DE FEATURES CON EL PRECIO\")\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(\"\\nTop 10 variables con correlaci贸n POSITIVA con el precio:\")\n",
    "for feat, val in corr_with_price.head(10).items():\n",
    "    print(f\"  {feat:30s} -> corr = {val:.3f}\")\n",
    "\n",
    "print(\"\\nTop 10 variables con correlaci贸n NEGATIVA con el precio:\")\n",
    "for feat, val in corr_with_price.tail(10).items():\n",
    "    print(f\"  {feat:30s} -> corr = {val:.3f}\")\n",
    "\n",
    "print(\"\\nUsa estas correlaciones para derivar recomendaciones a anfitriones en el reporte.\")\n",
    "print(\"Por ejemplo: enfocarse en las variables fuertemente positivas para justificar precios m谩s altos.\")\n",
    "\n",
    "# ==============================================================\n",
    "# 9. GRFICO DE LA ARQUITECTURA DEL MEJOR MODELO\n",
    "# ==============================================================\n",
    "\n",
    "try:\n",
    "    keras.utils.plot_model(\n",
    "        best_model,\n",
    "        to_file=\"arquitectura_mejor_modelo.png\",\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        expand_nested=True\n",
    "    )\n",
    "    print(\"\\nDiagrama de arquitectura guardado en 'arquitectura_mejor_modelo.png'.\")\n",
    "    print(\"Revisa este archivo PNG para incluirlo en tu reporte.\")\n",
    "except Exception as e:\n",
    "    print(\"\\nNo se pudo graficar la arquitectura del modelo.\")\n",
    "    print(\"Posibles causas: falta de graphviz/pydot. Error original:\")\n",
    "    print(e)\n",
    "\n",
    "# ==============================================================\n",
    "# 10. RESUMEN FINAL DEL MEJOR MODELO\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\n\\n===================================================\")\n",
    "print(\"RESUMEN DEL MEJOR MODELO DE REGRESIN (RED NEURONAL)\")\n",
    "print(\"===================================================\\n\")\n",
    "\n",
    "print(\">> Hiperpar谩metros seleccionados:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "\n",
    "print(\"\\n>> M茅tricas en VALIDACIN (mejor valor durante el entrenamiento):\")\n",
    "print(f\"   Mejor val_MAE: {best_val_mae:.4f}\")\n",
    "\n",
    "print(\"\\n>> M茅tricas en TEST (conjunto hold-out):\")\n",
    "print(f\"   MAE  (test): {test_mae:.4f}\")\n",
    "print(f\"   MSE  (test): {test_mse:.4f}\")\n",
    "print(f\"   RMSE (test): {test_rmse:.4f}\")\n",
    "print(f\"   R^2  (test): {test_r2:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Informaci贸n sobre arquitectura: capas, activaciones, etc.\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"\\n>> Arquitectura del modelo (best_model.summary()):\\n\")\n",
    "best_model.summary()\n",
    "\n",
    "# Contamos cu谩ntas capas densas lineales y no lineales hay\n",
    "num_dense_layers = 0\n",
    "num_linear_layers = 0\n",
    "num_nonlinear_layers = 0\n",
    "activations = []\n",
    "\n",
    "for layer in best_model.layers:\n",
    "    if isinstance(layer, keras.layers.Dense):\n",
    "        num_dense_layers += 1\n",
    "        act = layer.activation.__name__ if hasattr(layer, \"activation\") else \"none\"\n",
    "        activations.append((layer.name, act))\n",
    "        if act == \"linear\":\n",
    "            num_linear_layers += 1\n",
    "        else:\n",
    "            num_nonlinear_layers += 1\n",
    "\n",
    "print(\"\\n>> Detalle de capas densas y activaciones:\")\n",
    "for name, act in activations:\n",
    "    print(f\"   Capa: {name:20s} | Activaci贸n: {act}\")\n",
    "\n",
    "print(\"\\n>> Resumen de capas densas:\")\n",
    "print(f\"   Total capas densas: {num_dense_layers}\")\n",
    "print(f\"   Capas con activaci贸n NO lineal (ej. ReLU): {num_nonlinear_layers}\")\n",
    "print(f\"   Capas con activaci贸n lineal (incluye la de salida): {num_linear_layers}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Informaci贸n sobre variables usadas\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"\\n>> Variables de entrada utilizadas (features):\")\n",
    "print(f\"   N煤mero total de variables: {len(feature_names)}\")\n",
    "print(\"   Algunas de ellas (primeras 30):\")\n",
    "for f in feature_names[:30]:\n",
    "    print(\"    -\", f)\n",
    "\n",
    "print(\"\\nFin del script de regresi贸n con redes neuronales para Airbnb.\")\n",
    "print(\"Este modelo est谩 pensado para el cliente 'viajeros - clientes frecuentes',\")\n",
    "print(\"ya que permite estimar el precio por noche a partir de m煤ltiples caracter铆sticas \")\n",
    "print(\"de la propiedad y del host.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
